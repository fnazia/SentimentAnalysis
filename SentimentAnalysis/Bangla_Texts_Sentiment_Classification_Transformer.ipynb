{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eed6b6b",
   "metadata": {},
   "source": [
    "# PROJECT: Positive and Negative Sentiment Analysis Using Transformer\n",
    "\n",
    "This project aims to perform sentiment analysis of Bengali texts. The [dataset](https://data.mendeley.com/datasets/p6zc7krs37/4) used in this analysis consists of positive and negative reviews collected from Youtube Bengali drama $^{1}$. \n",
    "\n",
    "The model is formulated as a binary classification problem using attention network and CrossEntropyLoss function. The model structure is coded with the help of [Attention from scratch](https://medium.com/the-dl/transformers-from-scratch-in-pytorch-8777e346ca51)$^{2}$. In order to avoid the imbalance of the dataset, equal number of positive and negative reviews are taken as the training set. The model is trained on 1084 sentences, which comprise 80\\% of the dataset of sentences each containing 20 words or less. \n",
    "\n",
    "Approximately 86\\% of the test set of 138 samples is correctly classified by the trained model. It took around 50 epochs to reach this accuracy level. It is possible that better generalization ability of the model can be achieved with larger training set with higher variance. It is important to note here that the model's performance significantly depends on the nature of the training set as in some of the trial runs with a different training set (generated by random shuffle and choice) the model failed to produce any meaningful predictions. Both early stopping and learning rate scheduler are implemented to track the overfitting of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29094904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7061e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(seq_len, n_feature):\n",
    "    pos = torch.arange(seq_len, dtype = torch.float).reshape(1, -1, 1)\n",
    "    dim = torch.arange(n_feature, dtype = torch.float).reshape(1, 1, -1)\n",
    "    phase = pos / (1e4 ** torch.div(dim, n_feature, rounding_mode = 'trunc'))\n",
    "    pos_enc_out = torch.where(dim.long() % 2 == 0, torch.sin(phase), torch.cos(phase))\n",
    "    return pos_enc_out\n",
    "\n",
    "class AttentionHead(torch.nn.Module):\n",
    "    def __init__(self, n_embed, n_qkv):\n",
    "        super().__init__()\n",
    "        self.query = torch.nn.Linear(n_embed, n_qkv)\n",
    "        self.key = torch.nn.Linear(n_embed, n_qkv)\n",
    "        self.value = torch.nn.Linear(n_embed, n_qkv)\n",
    "        \n",
    "    def forward(self, query, key, value):\n",
    "        q = self.query(query)\n",
    "        k = self.key(key)\n",
    "        v = self.value(value)\n",
    "        \n",
    "        # scaled dot product\n",
    "        \n",
    "        attention = q.bmm(k.transpose(1, 2))\n",
    "        scale = q.size(-1)**0.5\n",
    "        scaled_attn = attention / scale\n",
    "        soft_scaled_attn = torch.nn.functional.softmax(scaled_attn, dim = -1)\n",
    "        attn_out = soft_scaled_attn.bmm(v)\n",
    "        \n",
    "        return attn_out\n",
    "    \n",
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, n_embed, n_qkv, n_head):\n",
    "        super().__init__()\n",
    "        self.attention_heads = torch.nn.ModuleList([AttentionHead(n_embed, n_qkv) for _ in range(n_head)])\n",
    "        self.linear = torch.nn.Linear(n_qkv * n_head, n_embed)\n",
    "        \n",
    "    def forward(self, query, key, value):\n",
    "        attn_heads_out = torch.cat([attn_h(query, key, value) for attn_h in self.attention_heads], dim = -1)\n",
    "        return self.linear(attn_heads_out)\n",
    "    \n",
    "class FeedForward(torch.nn.Module):\n",
    "    def __init__(self, n_embed, n_ffn):\n",
    "        super().__init__()\n",
    "        self.linear_1 = torch.nn.Linear(n_embed, n_ffn)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear_2 = torch.nn.Linear(n_ffn, n_embed)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        # No special operation; therefore, can be replaced by torch sequential\n",
    "        \n",
    "        ffn_out = self.linear_2(self.activation(self.linear_1(X)))\n",
    "        return ffn_out\n",
    "    \n",
    "class ResidualBlock(torch.nn.Module):\n",
    "    def __init__(self, sublayer, dim_sublayer, dropout):\n",
    "        super().__init__()\n",
    "        self.sublayer = sublayer\n",
    "        self.norm_layer = torch.nn.LayerNorm(dim_sublayer)\n",
    "        self.dropout_layer = torch.nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, *inputs):\n",
    "        out_sublayer = self.sublayer(*inputs)\n",
    "        out_residual = self.norm_layer(inputs[0] + self.dropout_layer(out_sublayer))\n",
    "        return out_residual\n",
    "    \n",
    "class EncoderLayer(torch.nn.Module):\n",
    "    def __init__(self, n_embed, n_qkv, n_head, n_ffn, dropout):\n",
    "        super().__init__()\n",
    "        self.multi_head_attention = ResidualBlock(MultiHeadAttention(n_embed, n_qkv, n_head), n_embed, dropout)\n",
    "        self.feed_forward = ResidualBlock(FeedForward(n_embed, n_ffn), n_embed, dropout)\n",
    "        \n",
    "    def forward(self, source):\n",
    "        mh_attn_out = self.multi_head_attention(source, source, source)\n",
    "        return self.feed_forward(mh_attn_out)\n",
    "    \n",
    "class EncoderBlock(torch.nn.Module):\n",
    "    def __init__(self, n_layers, n_embed, n_qkv, n_head, n_ffn, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder_layers = torch.nn.ModuleList([EncoderLayer(n_embed, n_qkv, n_head, n_ffn, dropout) \n",
    "                                                   for _ in range(n_layers)])\n",
    "        \n",
    "    def forward(self, source):\n",
    "        # add positional encoding\n",
    "        source += positional_encoding(source.shape[1], source.shape[2])\n",
    "        \n",
    "        for layer in self.encoder_layers:\n",
    "            source = layer(source)\n",
    "        \n",
    "        return source\n",
    "    \n",
    "class DecoderLayer(torch.nn.Module):\n",
    "    def __init__(self, n_embed, n_qkv, n_head, n_ffn, dropout):\n",
    "        super().__init__()\n",
    "        self.multi_head_attention_1 = ResidualBlock(MultiHeadAttention(n_embed, n_qkv, n_head), n_embed, dropout)\n",
    "        self.multi_head_attention_2 = ResidualBlock(MultiHeadAttention(n_embed, n_qkv, n_head), n_embed, dropout)\n",
    "        self.feed_forward = ResidualBlock(FeedForward(n_embed, n_ffn), n_embed, dropout)\n",
    "        \n",
    "    def forward(self, target, memory):\n",
    "        mh_attn_out_1 = self.multi_head_attention_1(target, target, target)\n",
    "        mh_attn_out_2 = self.multi_head_attention_2(mh_attn_out_1, memory, memory)\n",
    "        ffn_out = self.feed_forward(mh_attn_out_2)\n",
    "        \n",
    "        return ffn_out\n",
    "    \n",
    "class DecoderBlock(torch.nn.Module):\n",
    "    def __init__(self, n_layers, n_embed, n_qkv, n_head, n_ffn, dropout):\n",
    "        super().__init__()\n",
    "        self.decoder_layers = torch.nn.ModuleList([DecoderLayer(n_embed, n_qkv, n_head, n_ffn, dropout) for _ in range(n_layers)])\n",
    "        self.linear_out = torch.nn.Linear(n_ffn, n_out)\n",
    "        \n",
    "    def forward(self, target, memory):\n",
    "        target += positional_encoding(target.size[1], target.size[2])\n",
    "        for layer in self.decoder_layers:\n",
    "            target = layer(target, memory)\n",
    "        #output = self.linear_out(target)\n",
    "        \n",
    "        return target #torch.softmax(output)\n",
    "    \n",
    "class Transformer(torch.nn.Module):\n",
    "    def __init__(self, n_layers, n_embed, n_qkv, n_head, n_ffn, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = EncoderBlock(n_layers, n_embed, n_qkv, n_head, n_ffn, dropout)\n",
    "        self.decoder = DecoderBlock(n_layers, n_embed, n_qkv, n_head, n_ffn, dropout)\n",
    "        \n",
    "    def forward(self, source, target=None):\n",
    "        n_samples = source.shape[0]\n",
    "        memory = self.encoder(source)\n",
    "        if target is None:\n",
    "            return memory.reshape(n_samples, -1)\n",
    "        dec_out = self.decoder(target, memory)\n",
    "        return dec_out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e37f8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentiment classification Transformer model.  \n",
    "\n",
    "class SentimentAnalysis():\n",
    "    def __init__(self, seq_len, vocab_size, n_embed, n_out, n_layers, n_qkv, n_head, n_ffn, dropout):\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(vocab_size+1, n_embed, padding_idx = 0)\n",
    "        self.transformer_block = Transformer(n_layers, n_embed, n_qkv, n_head, n_ffn, dropout)\n",
    "        self.output_layer = torch.nn.Linear(n_embed * seq_len, n_out)\n",
    "        self.neunet = torch.nn.Sequential(OrderedDict([('embedding_layer', self.embedding),\n",
    "                                                       ('transformer_block', self.transformer_block), \n",
    "                                                       ('out_layer', self.output_layer)]))\n",
    "        \n",
    "        self.error_trace = []\n",
    "        self.error_trace_valid = []\n",
    "        \n",
    "    def train(self, XT, XTvalid, device, cpu_count=0, batch_size = None, learning_rate = 0.02, n_epochs = 200, early_stop_patience = 100):\n",
    "        n_patience = 0\n",
    "        best_error_diff = None\n",
    "        if batch_size is None:\n",
    "              batch_size = len(XT)\n",
    "        trainloader = torch.utils.data.DataLoader(XT, batch_size = batch_size, shuffle = True)\n",
    "        validloader = torch.utils.data.DataLoader(XTvalid, batch_size = batch_size, shuffle = False)\n",
    "        lossFunc = torch.nn.CrossEntropyLoss()\n",
    "        weight_decay = 1e-1\n",
    "        clip_norm = 5\n",
    "        optimizer = torch.optim.Adam(self.neunet.parameters(), lr = learning_rate, weight_decay=weight_decay)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=2)\n",
    "        self.neunet.to(device)\n",
    "        self.neunet.train()\n",
    "        \n",
    "        epoch_error_valid = []\n",
    "        for valid_batch in validloader:\n",
    "            Xv, Tv = valid_batch\n",
    "            Xv = Xv.to(device)\n",
    "            Tv = Tv.to(device)\n",
    "            Yvalid = self.test(Xv, device)\n",
    "            error_valid = lossFunc(Yvalid, Tv.long())\n",
    "            epoch_error_valid.append(error_valid.item())\n",
    "        self.print_accuracy(Yvalid, Tv, 'Validation')\n",
    "        validation_error = np.array(epoch_error_valid).mean()\n",
    "        self.error_trace_valid.append(validation_error)\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            epoch_error = []\n",
    "            \n",
    "            if best_error_diff is None:\n",
    "                best_error_diff = validation_error\n",
    "            elif best_error_diff < validation_error:\n",
    "                n_patience += 1\n",
    "                if n_patience == early_stop_patience:\n",
    "                    break\n",
    "            else:\n",
    "                best_error_diff = validation_error\n",
    "                n_patience = 0\n",
    "\n",
    "            for batch in trainloader:\n",
    "                X, T = batch\n",
    "                X = X.to(device)\n",
    "                T = T.to(device)\n",
    "                Y_pred = self.forward(X.long(), device) \n",
    "                optimizer.zero_grad()\n",
    "                error = lossFunc(Y_pred, T.long())\n",
    "                error.backward()\n",
    "                optimizer.step()\n",
    "                epoch_error.append(error.item())\n",
    "            self.error_trace.append(np.array(epoch_error).mean())\n",
    "            if epoch % 10 == 9:\n",
    "                print(f'Epoch: {epoch + 1} | Error: {self.error_trace[-1]:.3f}')\n",
    "                Ytrain = self.test(X, device)\n",
    "                self.print_accuracy(Ytrain, T, 'Training')\n",
    "                \n",
    "            epoch_error_valid = []\n",
    "            for valid_batch in validloader:\n",
    "                Xv, Tv = valid_batch\n",
    "                Xv = Xv.to(device)\n",
    "                Tv = Tv.to(device)\n",
    "                Yvalid = self.test(Xv, device)\n",
    "                error_valid = lossFunc(Yvalid, Tv.long())\n",
    "                epoch_error_valid.append(error_valid.item())\n",
    "            if epoch % 10 == 9:\n",
    "                self.print_accuracy(Yvalid, Tv, 'Validation')\n",
    "            validation_error = np.array(epoch_error_valid).mean()\n",
    "            self.error_trace_valid.append(validation_error)\n",
    "                \n",
    "    def forward(self, X, device):\n",
    "        X = self.neunet.embedding_layer(X)\n",
    "        X = self.neunet.transformer_block(X)\n",
    "        out = self.neunet[2:](X)\n",
    "        return out\n",
    "    \n",
    "    def test(self, X, device):\n",
    "        with torch.no_grad():\n",
    "            Y = self.forward(X.long(), device)\n",
    "        return Y\n",
    "\n",
    "    def print_accuracy(self, Y, T, data_set):\n",
    "        Y = torch.nn.functional.softmax(Y, dim = 1)\n",
    "        Y = Y.detach()\n",
    "        correct = torch.where(torch.argmax(Y, dim=1).reshape(-1) == T.reshape(-1))[0]\n",
    "        n_corr = correct.shape[0]\n",
    "        print(f'{data_set} set | Accuracy: {n_corr / T.shape[0]}')\n",
    "\n",
    "    def get_error_trace(self):\n",
    "        return self.error_trace, self.error_trace_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1541c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile DataLoad.py\n",
    "\n",
    "#import torch\n",
    "#import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "\n",
    "class LoadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, datalist, word2idx, seq_length):\n",
    "        self.datalist = datalist\n",
    "        self.word2idx = word2idx\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datalist)\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        seq, label = self.datalist[index]\n",
    "        seq_vector = np.array([self.word2idx.get(word, 0) for word in seq.split(' ')])\n",
    "        seq_transformed = self.transform(seq_vector)\n",
    "        return seq_transformed, int(label)\n",
    "\n",
    "    def transform(self, seq_vector):\n",
    "        seq_transformed = np.zeros(self.seq_length)\n",
    "        seq_transformed[:len(seq_vector)] = seq_vector\n",
    "        return seq_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a987b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training n_samples: 1084\n",
      "Validation n_samples: 134\n",
      "Test n_samples: 138\n"
     ]
    }
   ],
   "source": [
    "# Create training, validation, and test set\n",
    "\n",
    "neg_path = './p6zc7krs37-4/all_negative_3307.txt'\n",
    "pos_path = './p6zc7krs37-4/all_positive_8500.txt'\n",
    "\n",
    "punc_list = ['।', '?', '!', ',', ';', '\\'', '\\\"', '/', ':', '(', ')', '{', '}', '[', ']', '.', '*', '-', '_', '+', '=', '%']\n",
    "\n",
    "with open(neg_path) as f:\n",
    "    neglines = f.read().split('\\n')\n",
    "\n",
    "with open(pos_path) as f:\n",
    "    poslines = f.read().split('\\n')\n",
    "\n",
    "neglines_spaced = [''.join([c if c not in punc_list else ' '+c for c in line.strip()]) for line in neglines[:-1]]\n",
    "poslines_spaced = [''.join([c if c not in punc_list else ' '+c for c in line.strip()]) for line in poslines[:-1]]\n",
    "\n",
    "# Sentences with number of words less than 20 are taken for simplify the problem domain\n",
    "# Negative sentiment is labeled as 0 and positive sentiment is labeled as 1\n",
    "\n",
    "negset = [(re.sub('\\s+', ' ', line), 0) for line in neglines_spaced if len(line) < 20]\n",
    "posset = [(re.sub('\\s+', ' ', line), 1) for line in poslines_spaced if len(line) < 20]\n",
    "\n",
    "# Number of training samples is 80% of the dataset.\n",
    "\n",
    "n_train = int(len(negset)*0.8) # 0.2\n",
    "n_test = int(len(negset)*0.1) # 0.05\n",
    "train_set = negset[:n_train] + posset[:n_train]\n",
    "valid_set = negset[n_train:n_train+n_test] + posset[n_train:n_train+n_test]\n",
    "test_set = negset[n_train+n_test:] + posset[n_train+n_test:len(negset)]\n",
    "\n",
    "# Randomly shuffle all the samples in the training, validation, and test set\n",
    "\n",
    "random.shuffle(train_set)\n",
    "random.shuffle(valid_set)\n",
    "random.shuffle(test_set)\n",
    "print(f'Training n_samples: {len(train_set)}')\n",
    "print(f'Validation n_samples: {len(valid_set)}')\n",
    "print(f'Test n_samples: {len(test_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a74d9da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word to index dictionary and vice versa, \n",
    "# get vocab size and longest sequence length, \n",
    "# define number of target classes (sentiments to be predicted)\n",
    "\n",
    "dataset = negset + posset\n",
    "vocabs = list(set([word for line in dataset for word in line[0].split(' ')]))\n",
    "word2idx = {w: i for i, w in enumerate(vocabs, start = 1)}\n",
    "idx2word = {v: k for k, v in word2idx.items()}\n",
    "vocab_size = len(vocabs)\n",
    "seq_length_train = max([len(line[0]) for line in train_set])\n",
    "seq_length_valid = max([len(line[0]) for line in valid_set])\n",
    "seq_length_test = max([len(line[0]) for line in test_set])\n",
    "n_classes = len(list(set([line[1] for line in train_set])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eeaeb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: cpu\n"
     ]
    }
   ],
   "source": [
    "batch_size = None\n",
    "#cpu_count = 2 #mp.cpu_count()\n",
    "#print(f'cpu count: {cpu_count}')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device being used: {device}')\n",
    "\n",
    "seq_len = max(seq_length_train, seq_length_valid, seq_length_test)\n",
    "\n",
    "trainset = LoadDataset(train_set, word2idx, seq_length_train)\n",
    "validset = LoadDataset(valid_set, word2idx, seq_length_valid)\n",
    "testset = LoadDataset(test_set, word2idx, seq_length_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35561b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embed = 200 \n",
    "n_out = n_classes\n",
    "n_layers = 2\n",
    "n_qkv = 200\n",
    "n_head = 8 \n",
    "n_ffn = 100\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ca0007e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set | Accuracy: 0.4925373134328358\n",
      "Epoch: 10 | Error: 0.742\n",
      "Training set | Accuracy: 0.7601476014760148\n",
      "Validation set | Accuracy: 0.7388059701492538\n",
      "Epoch: 20 | Error: 0.329\n",
      "Training set | Accuracy: 0.8385608856088561\n",
      "Validation set | Accuracy: 0.8656716417910447\n",
      "Epoch: 30 | Error: 0.267\n",
      "Training set | Accuracy: 0.8939114391143912\n",
      "Validation set | Accuracy: 0.8880597014925373\n",
      "Epoch: 40 | Error: 0.203\n",
      "Training set | Accuracy: 0.9326568265682657\n",
      "Validation set | Accuracy: 0.9104477611940298\n",
      "Epoch: 50 | Error: 0.154\n",
      "Training set | Accuracy: 0.940959409594096\n",
      "Validation set | Accuracy: 0.917910447761194\n"
     ]
    }
   ],
   "source": [
    "# Train the model. \n",
    "\n",
    "train_data = trainset\n",
    "n_seq = seq_len\n",
    "sentnet = SentimentAnalysis(seq_len, vocab_size, n_embed, n_out, n_layers, n_qkv, n_head, n_ffn, dropout)\n",
    "sentnet.train(train_data, validset, device, batch_size = None, learning_rate = 0.001, n_epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fc6892e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set | Accuracy: 0.8623188405797102\n"
     ]
    }
   ],
   "source": [
    "# See model's performance on the unseen test set\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = len(test_set), shuffle = False)\n",
    "for X, T in testloader:        \n",
    "    Ytest = sentnet.test(X.to(device), device)\n",
    "sentnet.print_accuracy(Ytest, T.to(device), 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "790d9681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training and Validation Error plot\n",
    "\n",
    "plt.plot(sentnet.get_error_trace()[0], color = 'b', label = 'Training')\n",
    "plt.plot(sentnet.get_error_trace()[1], color = 'brown', label = 'Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb24d0b",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "1. Sazzed, Salim (2021), “Bangla ( Bengali ) sentiment analysis classification benchmark dataset corpus”, Mendeley Data, V4, doi: 10.17632/p6zc7krs37.4\n",
    "2. [Attention from scratch](https://medium.com/the-dl/transformers-from-scratch-in-pytorch-8777e346ca51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffcc179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
